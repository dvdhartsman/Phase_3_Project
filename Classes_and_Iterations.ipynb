{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.metrics import mean_squared_error, ConfusionMatrixDisplay, confusion_matrix, recall_score, \\\n",
    "    accuracy_score, precision_score, f1_score, plot_confusion_matrix, classification_report, log_loss\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the class that will store my data\n",
    "\n",
    "class Model():\n",
    "    model_list = []\n",
    "    model_df = pd.DataFrame(columns=['name','train_accuracy','train_prec','train_recall','train_f1','train_logloss',\\\n",
    "                                     'test_accuracy','test_prec','test_recall','test_f1','test_logloss'])\n",
    "    \n",
    "    def __init__(self, name, model, X_train, X_test, y_train, y_test):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.params = model.get_params\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        # Collection of training attributes\n",
    "        self.train_results = cross_validate(self.model, self.X_train, self.y_train, scoring=[\n",
    "            'precision_macro', 'accuracy', 'recall_macro', 'f1_macro', 'neg_log_loss'], n_jobs=4, verbose=1)\n",
    "        # Train metrics\n",
    "        self.train_acc = np.mean(self.train_results['test_accuracy'])\n",
    "        self.train_prec = np.mean(self.train_results['test_precision_macro'])\n",
    "        self.train_rec = np.mean(self.train_results['test_recall_macro'])\n",
    "        self.train_f1 = np.mean(self.train_results['test_f1_macro'])\n",
    "        self.train_logloss = -np.mean(self.train_results['test_neg_log_loss'])\n",
    "        \n",
    "        # Test metrics\n",
    "        self.y_pred_proba = self.model.predict_proba(self.X_test)  # accuracy\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        self.test_score = model.score(self.X_test, self.y_test)\n",
    "        self.test_recall = recall_score(self.y_test, self.y_pred, average='macro', zero_division=0)\n",
    "        self.test_prec = precision_score(self.y_test, self.y_pred, average='macro', zero_division=0)\n",
    "        self.test_log_loss = log_loss(self.y_test, self.y_pred_proba)\n",
    "        self.test_f1 = f1_score(self.y_test, self.y_pred, average='macro', zero_division=0)\n",
    "        \n",
    "        # Add model object to the class data container for access within the notebook\n",
    "        Model.model_list.append(self)\n",
    "        \n",
    "        # Dictionary containing all of the metrics to add to the dataframe\n",
    "        self.attributes = {'name':self.name, 'train_accuracy':self.train_acc, \"train_prec\": self.train_prec,\n",
    "                           \"train_recall\": self.train_rec, \"train_f1\": self.train_f1, \\\n",
    "                           \"train_logloss\": self.train_logloss, \\\n",
    "                          'test_accuracy':self.test_score, \"test_prec\": self.test_prec,\n",
    "                           \"test_recall\": self.test_recall, \"test_f1\": self.test_f1, \\\n",
    "                           \"test_logloss\": self.test_log_loss}\n",
    "        \n",
    "        # Add the metrics to the class dataframe\n",
    "        Model.model_df.loc[len(Model.model_df)] = self.attributes\n",
    "    \n",
    "    def __repr__(self):\n",
    "      return f\"Model name: ({self.model})\"\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def get_model_list(cls):\n",
    "        return cls.model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>scheme_name</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Mnyusi B</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>Ludewa</td>\n",
       "      <td>Mundindi</td>\n",
       "      <td>109</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Roman</td>\n",
       "      <td>False</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay annually</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Nyamara</td>\n",
       "      <td>Mara</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>Serengeti</td>\n",
       "      <td>Natta</td>\n",
       "      <td>280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2010</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>wug</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Majengo</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>Simanjiro</td>\n",
       "      <td>Ngorika</td>\n",
       "      <td>250</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Nyumba ya mungu pipe scheme</td>\n",
       "      <td>True</td>\n",
       "      <td>2009</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay per bucket</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>0</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mahakamani</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>90</td>\n",
       "      <td>63</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1986</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kyanyamisa</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Karagwe</td>\n",
       "      <td>Nyakasimbi</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n",
       "1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n",
       "2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n",
       "3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n",
       "4  19728         0.0    2011-07-13   Action In A           0       Artisan   \n",
       "\n",
       "   longitude   latitude              wpt_name  num_private  \\\n",
       "0  34.938093  -9.856322                  none            0   \n",
       "1  34.698766  -2.147466              Zahanati            0   \n",
       "2  37.460664  -3.821329           Kwa Mahundi            0   \n",
       "3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0   \n",
       "4  31.130847  -1.825359               Shuleni            0   \n",
       "\n",
       "                     basin  subvillage   region  region_code  district_code  \\\n",
       "0               Lake Nyasa    Mnyusi B   Iringa           11              5   \n",
       "1            Lake Victoria     Nyamara     Mara           20              2   \n",
       "2                  Pangani     Majengo  Manyara           21              4   \n",
       "3  Ruvuma / Southern Coast  Mahakamani   Mtwara           90             63   \n",
       "4            Lake Victoria  Kyanyamisa   Kagera           18              1   \n",
       "\n",
       "         lga        ward  population public_meeting              recorded_by  \\\n",
       "0     Ludewa    Mundindi         109           True  GeoData Consultants Ltd   \n",
       "1  Serengeti       Natta         280            NaN  GeoData Consultants Ltd   \n",
       "2  Simanjiro     Ngorika         250           True  GeoData Consultants Ltd   \n",
       "3   Nanyumbu    Nanyumbu          58           True  GeoData Consultants Ltd   \n",
       "4    Karagwe  Nyakasimbi           0           True  GeoData Consultants Ltd   \n",
       "\n",
       "  scheme_management                  scheme_name permit  construction_year  \\\n",
       "0               VWC                        Roman  False               1999   \n",
       "1             Other                          NaN   True               2010   \n",
       "2               VWC  Nyumba ya mungu pipe scheme   True               2009   \n",
       "3               VWC                          NaN   True               1986   \n",
       "4               NaN                          NaN   True                  0   \n",
       "\n",
       "  extraction_type extraction_type_group extraction_type_class management  \\\n",
       "0         gravity               gravity               gravity        vwc   \n",
       "1         gravity               gravity               gravity        wug   \n",
       "2         gravity               gravity               gravity        vwc   \n",
       "3     submersible           submersible           submersible        vwc   \n",
       "4         gravity               gravity               gravity      other   \n",
       "\n",
       "  management_group         payment payment_type water_quality quality_group  \\\n",
       "0       user-group    pay annually     annually          soft          good   \n",
       "1       user-group       never pay    never pay          soft          good   \n",
       "2       user-group  pay per bucket   per bucket          soft          good   \n",
       "3       user-group       never pay    never pay          soft          good   \n",
       "4            other       never pay    never pay          soft          good   \n",
       "\n",
       "       quantity quantity_group                source           source_type  \\\n",
       "0        enough         enough                spring                spring   \n",
       "1  insufficient   insufficient  rainwater harvesting  rainwater harvesting   \n",
       "2        enough         enough                   dam                   dam   \n",
       "3           dry            dry           machine dbh              borehole   \n",
       "4      seasonal       seasonal  rainwater harvesting  rainwater harvesting   \n",
       "\n",
       "  source_class              waterpoint_type waterpoint_type_group  \n",
       "0  groundwater           communal standpipe    communal standpipe  \n",
       "1      surface           communal standpipe    communal standpipe  \n",
       "2      surface  communal standpipe multiple    communal standpipe  \n",
       "3  groundwater  communal standpipe multiple    communal standpipe  \n",
       "4      surface           communal standpipe    communal standpipe  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the csv file, print its shape, and examine the first 5 rows of data\n",
    "original_features_df = pd.read_csv('./Data/4910797b-ee55-40a7-8668-10efd5c1b960.csv')\n",
    "print(original_features_df.shape)\n",
    "original_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/samalainabayeva/Desktop/Water Project CSVs/updated_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the smaller data set to be used in grid searches\n",
    "sample_data = df.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split on the data\n",
    "X = df.drop(\"Target\", axis = 1)\n",
    "y = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines for iterating over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipelines for numeric and categorical data\n",
    "\n",
    "subpipe_numerics = Pipeline(steps=[\n",
    "    ('mean_impute', SimpleImputer(add_indicator=True, strategy='mean')),\n",
    "    ('ss', StandardScaler())\n",
    "], verbose=True)\n",
    "\n",
    "sub_pipe_cat = Pipeline(steps=[\n",
    "    \n",
    "    ('cat_impute', SimpleImputer(strategy='most_frequent', add_indicator=True)),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=True))  \n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer to implement the above sub-pipelines\n",
    "\n",
    "CT = ColumnTransformer(transformers=[\n",
    "    ('subpipe_numerics', subpipe_numerics, selector(dtype_include=np.number)),\n",
    "    ('subpipe_cat', sub_pipe_cat, selector(dtype_include=object))\n",
    "], remainder='passthrough', n_jobs= 4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final pipeline for model instantiation.\n",
    "dummy_model = Pipeline(steps=[\n",
    "    ('CT', CT),\n",
    "    ('dummy', DummyClassifier(strategy=\"most_frequent\"))\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_logistic = Pipeline(steps=[\n",
    "    ('CT', CT),\n",
    "    ('baseline_log', LogisticRegression(verbose=1, n_jobs=4))\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing a starting dictionary of parameters and optional values\n",
    "parameters = {\n",
    "    \"baseline_log__penalty\": [\"l1\", \"l2\"],\n",
    "    \"baseline_log__tol\": [.0001, .001, .01],\n",
    "    \"baseline_log__C\": [1, .1, .01],\n",
    "    \"baseline_log__fit_intercept\": [True, False],\n",
    "    \"baseline_log__solver\": ['newton-cg', 'sag', 'lbfgs'],\n",
    "    \"baseline_log__max_iter\": [100, 250, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_logistic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0a98d9f5c8a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m grid_search = GridSearchCV(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_logistic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'baseline_logistic' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=baseline_logistic,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_pipeline = ImPipeline(steps=[\n",
    "    (\"CT\", CT),\n",
    "    (\"smote\", SMOTE(n_jobs= 4, sampling_strategy='auto')),  \n",
    "    # auto is both default and equivalent to 'not_majority'\n",
    "    \n",
    "    ('baseline_log', LogisticRegression(verbose=1, n_jobs=4)), \n",
    "    # using the same hyper-parameters as baseline/best model\n",
    "], verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a reference for the previous models\n",
    "previous_models_df = pd.read_csv('/Users/samalainabayeva/Desktop/Water Project CSVs/abridged_table.csv')\n",
    "second_previous = pd.read_csv('/Users/samalainabayeva/Desktop/Water Project CSVs/2nd_add_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_log_loss</th>\n",
       "      <th>name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_logloss</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>train_prec</th>\n",
       "      <th>train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.542334</td>\n",
       "      <td>15.807208</td>\n",
       "      <td>0.545320</td>\n",
       "      <td>15.704096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>logistic_1</td>\n",
       "      <td>0.771762</td>\n",
       "      <td>0.577305</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.598705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>grid_logistic_1</td>\n",
       "      <td>0.766981</td>\n",
       "      <td>0.586082</td>\n",
       "      <td>0.763030</td>\n",
       "      <td>0.596011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>smote_1</td>\n",
       "      <td>0.683659</td>\n",
       "      <td>0.720839</td>\n",
       "      <td>0.669091</td>\n",
       "      <td>0.733580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lr_C.01_mi200_solv_n.cg</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614420</td>\n",
       "      <td>0.750976</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>c.01_mi200_svr_ncg_tol_1</td>\n",
       "      <td>0.677621</td>\n",
       "      <td>0.747923</td>\n",
       "      <td>0.668215</td>\n",
       "      <td>0.773572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>poly1_lr_C.01_mi200_solv_n.cg</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614420</td>\n",
       "      <td>0.750976</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>poly2_lr_C.01_mi1000_solv_n.cg</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614420</td>\n",
       "      <td>0.750976</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>saga_l1_mi1000</td>\n",
       "      <td>0.727452</td>\n",
       "      <td>0.663176</td>\n",
       "      <td>0.728013</td>\n",
       "      <td>0.699459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614422</td>\n",
       "      <td>0.750909</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs_fi</td>\n",
       "      <td>0.753401</td>\n",
       "      <td>0.614213</td>\n",
       "      <td>0.751246</td>\n",
       "      <td>0.642047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>new_cg</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614213</td>\n",
       "      <td>0.751313</td>\n",
       "      <td>0.642047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>new_low_c</td>\n",
       "      <td>0.730640</td>\n",
       "      <td>0.678024</td>\n",
       "      <td>0.731582</td>\n",
       "      <td>0.721139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>numeric_only</td>\n",
       "      <td>0.615690</td>\n",
       "      <td>0.678024</td>\n",
       "      <td>0.620741</td>\n",
       "      <td>0.721139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>dropped3cols</td>\n",
       "      <td>0.727520</td>\n",
       "      <td>0.678024</td>\n",
       "      <td>0.727340</td>\n",
       "      <td>0.721139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>minmax_baseline</td>\n",
       "      <td>0.771762</td>\n",
       "      <td>0.577305</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.598705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>median_fill, min_max</td>\n",
       "      <td>0.771762</td>\n",
       "      <td>0.577305</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.598705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>median_fill_2, min_max</td>\n",
       "      <td>0.771560</td>\n",
       "      <td>0.577373</td>\n",
       "      <td>0.764714</td>\n",
       "      <td>0.598045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dummy_classifier</td>\n",
       "      <td>0.54532</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>15.704096</td>\n",
       "      <td>0.181773</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.542334</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>15.807208</td>\n",
       "      <td>0.180778</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dummy_classifier</td>\n",
       "      <td>0.54532</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>15.704096</td>\n",
       "      <td>0.181773</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.542334</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>15.807208</td>\n",
       "      <td>0.180778</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                            Name  train_score  train_log_loss  \\\n",
       "0            0                           dummy     0.542334       15.807208   \n",
       "1            1                      logistic_1     0.771762        0.577305   \n",
       "2            2                 grid_logistic_1     0.766981        0.586082   \n",
       "3            3                         smote_1     0.683659        0.720839   \n",
       "4            4         lr_C.01_mi200_solv_n.cg     0.753378        0.614420   \n",
       "5            5        c.01_mi200_svr_ncg_tol_1     0.677621        0.747923   \n",
       "6            6   poly1_lr_C.01_mi200_solv_n.cg     0.753378        0.614420   \n",
       "7            7  poly2_lr_C.01_mi1000_solv_n.cg     0.753378        0.614420   \n",
       "8            8                  saga_l1_mi1000     0.727452        0.663176   \n",
       "9            9                           lbfgs     0.753378        0.614422   \n",
       "10          10                        lbfgs_fi     0.753401        0.614213   \n",
       "11          11                          new_cg     0.753378        0.614213   \n",
       "12          12                       new_low_c     0.730640        0.678024   \n",
       "13          13                    numeric_only     0.615690        0.678024   \n",
       "14          14                    dropped3cols     0.727520        0.678024   \n",
       "15          15                 minmax_baseline     0.771762        0.577305   \n",
       "16          16            median_fill, min_max     0.771762        0.577305   \n",
       "17          17          median_fill_2, min_max     0.771560        0.577373   \n",
       "18          18                             NaN          NaN             NaN   \n",
       "19          19                             NaN          NaN             NaN   \n",
       "\n",
       "    test_score  test_log_loss              name  test_accuracy   test_f1  \\\n",
       "0     0.545320      15.704096               NaN            NaN       NaN   \n",
       "1     0.763636       0.598705               NaN            NaN       NaN   \n",
       "2     0.763030       0.596011               NaN            NaN       NaN   \n",
       "3     0.669091       0.733580               NaN            NaN       NaN   \n",
       "4     0.750976       0.642552               NaN            NaN       NaN   \n",
       "5     0.668215       0.773572               NaN            NaN       NaN   \n",
       "6     0.750976       0.642552               NaN            NaN       NaN   \n",
       "7     0.750976       0.642552               NaN            NaN       NaN   \n",
       "8     0.728013       0.699459               NaN            NaN       NaN   \n",
       "9     0.750909       0.642552               NaN            NaN       NaN   \n",
       "10    0.751246       0.642047               NaN            NaN       NaN   \n",
       "11    0.751313       0.642047               NaN            NaN       NaN   \n",
       "12    0.731582       0.721139               NaN            NaN       NaN   \n",
       "13    0.620741       0.721139               NaN            NaN       NaN   \n",
       "14    0.727340       0.721139               NaN            NaN       NaN   \n",
       "15    0.763636       0.598705               NaN            NaN       NaN   \n",
       "16    0.763636       0.598705               NaN            NaN       NaN   \n",
       "17    0.764714       0.598045               NaN            NaN       NaN   \n",
       "18         NaN            NaN  dummy_classifier        0.54532  0.235257   \n",
       "19         NaN            NaN  dummy_classifier        0.54532  0.235257   \n",
       "\n",
       "    test_logloss  test_prec  test_recall  train_accuracy  train_f1  \\\n",
       "0            NaN        NaN          NaN             NaN       NaN   \n",
       "1            NaN        NaN          NaN             NaN       NaN   \n",
       "2            NaN        NaN          NaN             NaN       NaN   \n",
       "3            NaN        NaN          NaN             NaN       NaN   \n",
       "4            NaN        NaN          NaN             NaN       NaN   \n",
       "5            NaN        NaN          NaN             NaN       NaN   \n",
       "6            NaN        NaN          NaN             NaN       NaN   \n",
       "7            NaN        NaN          NaN             NaN       NaN   \n",
       "8            NaN        NaN          NaN             NaN       NaN   \n",
       "9            NaN        NaN          NaN             NaN       NaN   \n",
       "10           NaN        NaN          NaN             NaN       NaN   \n",
       "11           NaN        NaN          NaN             NaN       NaN   \n",
       "12           NaN        NaN          NaN             NaN       NaN   \n",
       "13           NaN        NaN          NaN             NaN       NaN   \n",
       "14           NaN        NaN          NaN             NaN       NaN   \n",
       "15           NaN        NaN          NaN             NaN       NaN   \n",
       "16           NaN        NaN          NaN             NaN       NaN   \n",
       "17           NaN        NaN          NaN             NaN       NaN   \n",
       "18     15.704096   0.181773     0.333333        0.542334  0.234421   \n",
       "19     15.704096   0.181773     0.333333        0.542334  0.234421   \n",
       "\n",
       "    train_logloss  train_prec  train_recall  \n",
       "0             NaN         NaN           NaN  \n",
       "1             NaN         NaN           NaN  \n",
       "2             NaN         NaN           NaN  \n",
       "3             NaN         NaN           NaN  \n",
       "4             NaN         NaN           NaN  \n",
       "5             NaN         NaN           NaN  \n",
       "6             NaN         NaN           NaN  \n",
       "7             NaN         NaN           NaN  \n",
       "8             NaN         NaN           NaN  \n",
       "9             NaN         NaN           NaN  \n",
       "10            NaN         NaN           NaN  \n",
       "11            NaN         NaN           NaN  \n",
       "12            NaN         NaN           NaN  \n",
       "13            NaN         NaN           NaN  \n",
       "14            NaN         NaN           NaN  \n",
       "15            NaN         NaN           NaN  \n",
       "16            NaN         NaN           NaN  \n",
       "17            NaN         NaN           NaN  \n",
       "18      15.807208    0.180778      0.333333  \n",
       "19      15.807208    0.180778      0.333333  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.669742</td>\n",
       "      <td>0.665051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Smote_grid1</td>\n",
       "      <td>0.669742</td>\n",
       "      <td>0.665051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline_log</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.765051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline_log</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.765051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline_log_grid</td>\n",
       "      <td>0.766846</td>\n",
       "      <td>0.764781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>poly1</td>\n",
       "      <td>0.772435</td>\n",
       "      <td>0.768822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Poly_grid_1</td>\n",
       "      <td>0.772435</td>\n",
       "      <td>0.768822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>poly2</td>\n",
       "      <td>0.770168</td>\n",
       "      <td>0.766128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Poly_grid_3</td>\n",
       "      <td>0.772435</td>\n",
       "      <td>0.768822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>poly_smote</td>\n",
       "      <td>0.684040</td>\n",
       "      <td>0.677980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>dates1</td>\n",
       "      <td>0.768822</td>\n",
       "      <td>0.763771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Dates_grid</td>\n",
       "      <td>0.772256</td>\n",
       "      <td>0.767946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0               Name  train_score  test_score\n",
       "0            0                  0     0.000000    0.000000\n",
       "1            0           baseline     0.669742    0.665051\n",
       "2            0        Smote_grid1     0.669742    0.665051\n",
       "3            0       Baseline_log     0.769921    0.765051\n",
       "4            0       Baseline_log     0.769921    0.765051\n",
       "5            0  Baseline_log_grid     0.766846    0.764781\n",
       "6            0              poly1     0.772435    0.768822\n",
       "7            0        Poly_grid_1     0.772435    0.768822\n",
       "8            0              poly2     0.770168    0.766128\n",
       "9            0        Poly_grid_3     0.772435    0.768822\n",
       "10           0         poly_smote     0.684040    0.677980\n",
       "11           0             dates1     0.768822    0.763771\n",
       "12           0         Dates_grid     0.772256    0.767946"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "- Changing sampling strategy to \"auto\" made no difference in SMOTE hyperparameters.\n",
    "- Baseline log grid slightly worse than the uncalibrated logistic regression\n",
    "- For polynomial features, the grid search did not improve the default settings at all, still not overfit\n",
    "- After a 2 hour grid search, the best model only equals the best score thus far, still without overfitting, but without any improvement either.\n",
    "- Polynomial degree 2 + smote improved upon the baseline smote, but still performed worse than other models\n",
    "\n",
    "- Adding the dates_passed column improved the model very slightly. I will now re-check cleaning/feature selection.\n",
    "#### Returning to the baseline logistic regression model and modifying from there\n",
    "- Baseline Logistic Regression continues to be the best model\n",
    "- StandardScaler and MinMaxScaler produced the same exact results\n",
    "- Median fill and mean fill produced identical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
