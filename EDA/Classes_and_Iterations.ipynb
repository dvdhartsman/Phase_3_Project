{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.metrics import mean_squared_error, ConfusionMatrixDisplay, confusion_matrix, recall_score, \\\n",
    "    accuracy_score, precision_score, f1_score, plot_confusion_matrix, classification_report, log_loss\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the class that will store my data\n",
    "\n",
    "class Model():\n",
    "    model_list = []\n",
    "    model_df = pd.DataFrame(columns=['name','train_accuracy','train_prec','train_recall','train_f1','train_logloss',\\\n",
    "                                     'test_accuracy','test_prec','test_recall','test_f1','test_logloss'])\n",
    "    \n",
    "    def __init__(self, name, model, X_train, X_test, y_train, y_test):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.params = model.get_params\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        # Collection of training attributes\n",
    "        self.train_results = cross_validate(self.model, self.X_train, self.y_train, scoring=[\n",
    "            'precision_macro', 'accuracy', 'recall_macro', 'f1_macro', 'neg_log_loss'], n_jobs=4, verbose=1)\n",
    "        # Train metrics\n",
    "        self.train_acc = np.mean(self.train_results['test_accuracy'])\n",
    "        self.train_prec = np.mean(self.train_results['test_precision_macro'])\n",
    "        self.train_rec = np.mean(self.train_results['test_recall_macro'])\n",
    "        self.train_f1 = np.mean(self.train_results['test_f1_macro'])\n",
    "        self.train_logloss = -np.mean(self.train_results['test_neg_log_loss'])\n",
    "        \n",
    "        # Test metrics\n",
    "        self.y_pred_proba = self.model.predict_proba(self.X_test)  # accuracy\n",
    "        self.y_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        self.test_score = model.score(self.X_test, self.y_test)\n",
    "        self.test_recall = recall_score(self.y_test, self.y_pred, average='macro', zero_division=0)\n",
    "        self.test_prec = precision_score(self.y_test, self.y_pred, average='macro', zero_division=0)\n",
    "        self.test_log_loss = log_loss(self.y_test, self.y_pred_proba)\n",
    "        self.test_f1 = f1_score(self.y_test, self.y_pred, average='macro', zero_division=0)\n",
    "        \n",
    "        # Add model object to the class data container for access within the notebook\n",
    "        Model.model_list.append(self)\n",
    "        \n",
    "        # Dictionary containing all of the metrics to add to the dataframe\n",
    "        self.attributes = {'name':self.name, 'train_accuracy':self.train_acc, \"train_prec\": self.train_prec,\n",
    "                           \"train_recall\": self.train_rec, \"train_f1\": self.train_f1, \\\n",
    "                           \"train_logloss\": self.train_logloss, \\\n",
    "                          'test_accuracy':self.test_score, \"test_prec\": self.test_prec,\n",
    "                           \"test_recall\": self.test_recall, \"test_f1\": self.test_f1, \\\n",
    "                           \"test_logloss\": self.test_log_loss}\n",
    "        \n",
    "        # Add the metrics to the class dataframe\n",
    "        Model.model_df.loc[len(Model.model_df)] = self.attributes\n",
    "    \n",
    "    def __repr__(self):\n",
    "      return f\"Model name: ({self.model})\"\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def get_model_list(cls):\n",
    "        return cls.model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>ward</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>scheme_name</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Mnyusi B</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>Ludewa</td>\n",
       "      <td>Mundindi</td>\n",
       "      <td>109</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Roman</td>\n",
       "      <td>False</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay annually</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Nyamara</td>\n",
       "      <td>Mara</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>Serengeti</td>\n",
       "      <td>Natta</td>\n",
       "      <td>280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2010</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>wug</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Majengo</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>Simanjiro</td>\n",
       "      <td>Ngorika</td>\n",
       "      <td>250</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>Nyumba ya mungu pipe scheme</td>\n",
       "      <td>True</td>\n",
       "      <td>2009</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>pay per bucket</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>0</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mahakamani</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>90</td>\n",
       "      <td>63</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>Nanyumbu</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1986</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>submersible</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kyanyamisa</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Karagwe</td>\n",
       "      <td>Nyakasimbi</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n",
       "1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n",
       "2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n",
       "3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n",
       "4  19728         0.0    2011-07-13   Action In A           0       Artisan   \n",
       "\n",
       "   longitude   latitude              wpt_name  num_private  \\\n",
       "0  34.938093  -9.856322                  none            0   \n",
       "1  34.698766  -2.147466              Zahanati            0   \n",
       "2  37.460664  -3.821329           Kwa Mahundi            0   \n",
       "3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0   \n",
       "4  31.130847  -1.825359               Shuleni            0   \n",
       "\n",
       "                     basin  subvillage   region  region_code  district_code  \\\n",
       "0               Lake Nyasa    Mnyusi B   Iringa           11              5   \n",
       "1            Lake Victoria     Nyamara     Mara           20              2   \n",
       "2                  Pangani     Majengo  Manyara           21              4   \n",
       "3  Ruvuma / Southern Coast  Mahakamani   Mtwara           90             63   \n",
       "4            Lake Victoria  Kyanyamisa   Kagera           18              1   \n",
       "\n",
       "         lga        ward  population public_meeting              recorded_by  \\\n",
       "0     Ludewa    Mundindi         109           True  GeoData Consultants Ltd   \n",
       "1  Serengeti       Natta         280            NaN  GeoData Consultants Ltd   \n",
       "2  Simanjiro     Ngorika         250           True  GeoData Consultants Ltd   \n",
       "3   Nanyumbu    Nanyumbu          58           True  GeoData Consultants Ltd   \n",
       "4    Karagwe  Nyakasimbi           0           True  GeoData Consultants Ltd   \n",
       "\n",
       "  scheme_management                  scheme_name permit  construction_year  \\\n",
       "0               VWC                        Roman  False               1999   \n",
       "1             Other                          NaN   True               2010   \n",
       "2               VWC  Nyumba ya mungu pipe scheme   True               2009   \n",
       "3               VWC                          NaN   True               1986   \n",
       "4               NaN                          NaN   True                  0   \n",
       "\n",
       "  extraction_type extraction_type_group extraction_type_class management  \\\n",
       "0         gravity               gravity               gravity        vwc   \n",
       "1         gravity               gravity               gravity        wug   \n",
       "2         gravity               gravity               gravity        vwc   \n",
       "3     submersible           submersible           submersible        vwc   \n",
       "4         gravity               gravity               gravity      other   \n",
       "\n",
       "  management_group         payment payment_type water_quality quality_group  \\\n",
       "0       user-group    pay annually     annually          soft          good   \n",
       "1       user-group       never pay    never pay          soft          good   \n",
       "2       user-group  pay per bucket   per bucket          soft          good   \n",
       "3       user-group       never pay    never pay          soft          good   \n",
       "4            other       never pay    never pay          soft          good   \n",
       "\n",
       "       quantity quantity_group                source           source_type  \\\n",
       "0        enough         enough                spring                spring   \n",
       "1  insufficient   insufficient  rainwater harvesting  rainwater harvesting   \n",
       "2        enough         enough                   dam                   dam   \n",
       "3           dry            dry           machine dbh              borehole   \n",
       "4      seasonal       seasonal  rainwater harvesting  rainwater harvesting   \n",
       "\n",
       "  source_class              waterpoint_type waterpoint_type_group  \n",
       "0  groundwater           communal standpipe    communal standpipe  \n",
       "1      surface           communal standpipe    communal standpipe  \n",
       "2      surface  communal standpipe multiple    communal standpipe  \n",
       "3  groundwater  communal standpipe multiple    communal standpipe  \n",
       "4      surface           communal standpipe    communal standpipe  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the csv file, print its shape, and examine the first 5 rows of data\n",
    "original_features_df = pd.read_csv('../Data/4910797b-ee55-40a7-8668-10efd5c1b960.csv')\n",
    "print(original_features_df.shape)\n",
    "original_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/updated_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>management</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>dates_passed</th>\n",
       "      <th>Target</th>\n",
       "      <th>ward</th>\n",
       "      <th>scheme_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Other</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>Ludewa</td>\n",
       "      <td>109.0</td>\n",
       "      <td>True</td>\n",
       "      <td>VWC</td>\n",
       "      <td>False</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>Roman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>1399</td>\n",
       "      <td>other</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Other</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>Serengeti</td>\n",
       "      <td>280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>True</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>wug</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>Natta</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh funder  gps_height installer          basin subvillage  \\\n",
       "0      6000.0  Roman        1390     Roman     Lake Nyasa      Other   \n",
       "1         NaN  other        1399     other  Lake Victoria      Other   \n",
       "\n",
       "   region_code  district_code        lga  population public_meeting  \\\n",
       "0           11              5     Ludewa       109.0           True   \n",
       "1           20              2  Serengeti       280.0            NaN   \n",
       "\n",
       "  scheme_management permit  construction_year extraction_type management  \\\n",
       "0               VWC  False             1999.0         gravity        vwc   \n",
       "1             Other   True             2010.0         gravity        wug   \n",
       "\n",
       "  management_group payment_type water_quality      quantity  \\\n",
       "0       user-group     annually          soft        enough   \n",
       "1       user-group    never pay          soft  insufficient   \n",
       "\n",
       "                 source source_class     waterpoint_type  dates_passed  \\\n",
       "0                spring  groundwater  communal standpipe           995   \n",
       "1  rainwater harvesting      surface  communal standpipe           272   \n",
       "\n",
       "   Target   ward scheme_name  \n",
       "0       0  other       Roman  \n",
       "1       0  Natta         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df.select_dtypes(include=np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breaking data into Train/Test split, smaller sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the smaller data set to be used in grid searches\n",
    "sample_data = df.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = sample_data.drop(\"Target\", axis = 1)\n",
    "y_sample = sample_data['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split on the data\n",
    "X = df.drop(\"Target\", axis = 1)\n",
    "y = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines for iterating over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipelines for numeric and categorical data\n",
    "\n",
    "subpipe_numerics = Pipeline(steps=[\n",
    "    ('mean_impute', SimpleImputer(add_indicator=True, strategy='mean')),\n",
    "    ('ss', StandardScaler()),\n",
    "], verbose=True)\n",
    "\n",
    "sub_pipe_cat = Pipeline(steps=[\n",
    "    \n",
    "    ('cat_impute', SimpleImputer(strategy='most_frequent', add_indicator=True)),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=True))  \n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer to implement the above sub-pipelines\n",
    "\n",
    "CT = ColumnTransformer(transformers=[\n",
    "    ('subpipe_numerics', subpipe_numerics, selector(dtype_include=np.number)),\n",
    "    ('subpipe_cat', sub_pipe_cat, selector(dtype_include=object))\n",
    "], remainder='passthrough', n_jobs= 4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final pipeline for model instantiation.\n",
    "dummy_model = Pipeline(steps=[\n",
    "    ('CT', CT),\n",
    "    ('dummy', DummyClassifier(strategy=\"most_frequent\"))\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbfgs = Pipeline(steps=[\n",
    "    ('CT', CT),\n",
    "    ('baseline_log', LogisticRegression(C=.01, max_iter=1000, solver='lbfgs', verbose=1, n_jobs=4))\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing a starting dictionary of parameters and optional values\n",
    "parameters = {\n",
    "    \"baseline_log__penalty\": [\"l1\", \"l2\"],\n",
    "    \"baseline_log__tol\": [.0001, .001, .01],\n",
    "    \"baseline_log__C\": [1, .1, .01],\n",
    "    \"baseline_log__fit_intercept\": [True, False],\n",
    "    \"baseline_log__solver\": ['newton-cg', 'sag', 'lbfgs'],\n",
    "    \"baseline_log__max_iter\": [100, 250, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_logistic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0a98d9f5c8a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m grid_search = GridSearchCV(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_logistic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'baseline_logistic' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=#baseline_logistic,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smote Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_dict = ImPipeline(steps=[\n",
    "    (\"CT\", CT),\n",
    "    (\"smote\", SMOTE(n_jobs= 4, sampling_strategy={0:24161,1:15000,2: 17146})),  \n",
    "    # auto is both default and equivalent to 'not_majority'\n",
    "    \n",
    "    ('baseline_log', LogisticRegression(verbose=1, n_jobs=4)), \n",
    "    # using the same hyper-parameters as baseline/best model\n",
    "], verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 3) Processing CT, total=   9.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing smote, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 3 of 3) Processing baseline_log, total=   3.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('CT',\n",
       "                 ColumnTransformer(n_jobs=4, remainder='passthrough',\n",
       "                                   transformers=[('subpipe_numerics',\n",
       "                                                  Pipeline(steps=[('mean_impute',\n",
       "                                                                   SimpleImputer(add_indicator=True)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())],\n",
       "                                                           verbose=True),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fae0a502250>),\n",
       "                                                 ('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('cat_impute',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))],\n",
       "                                                           verbose=True),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fae0a502be0>)],\n",
       "                                   verbose=True)),\n",
       "                ('smote',\n",
       "                 SMOTE(n_jobs=4,\n",
       "                       sampling_strategy={0: 24161, 1: 15000, 2: 17146})),\n",
       "                ('baseline_log', LogisticRegression(n_jobs=4, verbose=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_dict.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plot_confusion_matrix(smote_dict, X_test, y_test, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8098\n",
       "2    5678\n",
       "1    1074\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a reference for the previous models\n",
    "previous_models_df = pd.read_csv('/Users/samalainabayeva/Desktop/Water Project CSVs/abridged_table.csv')\n",
    "second_previous = pd.read_csv('/Users/samalainabayeva/Desktop/Water Project CSVs/2nd_add_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 3) Processing CT, total=   9.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing smote, total=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 3 of 3) Processing baseline_log, total=   5.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('CT',\n",
       "                 ColumnTransformer(n_jobs=4, remainder='passthrough',\n",
       "                                   transformers=[('subpipe_numerics',\n",
       "                                                  Pipeline(steps=[('mean_impute',\n",
       "                                                                   SimpleImputer(add_indicator=True)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  ('poly',\n",
       "                                                                   PolynomialFeatures(interaction_only=True))],\n",
       "                                                           verbose=True),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f82e87f5820>),\n",
       "                                                 ('sub...\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))],\n",
       "                                                           verbose=True),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f82e87f5910>)],\n",
       "                                   verbose=True)),\n",
       "                ('smote',\n",
       "                 SMOTE(n_jobs=4,\n",
       "                       sampling_strategy={0: 24161, 1: 15000, 2: 17146})),\n",
       "                ('baseline_log', LogisticRegression(n_jobs=4, verbose=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_dict.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_log__C': 1,\n",
       " 'baseline_log__fit_intercept': True,\n",
       " 'baseline_log__max_iter': 100,\n",
       " 'baseline_log__penalty': 'l2',\n",
       " 'baseline_log__solver': 'sag',\n",
       " 'baseline_log__tol': 0.0001}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing CT, total=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n",
      "[Pipeline] ...... (step 2 of 2) Processing baseline_log, total=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samalainabayeva/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "grid_log = grid_search.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Instantion/variable storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Cell to contain the names/hyperparameters of models\n",
    "\n",
    "# X_train, X_test, y_train, y_test  # for quick copy and paste\n",
    "\n",
    "# dummy_model: 'dummy', DummyClassifier(strategy=\"most_frequent\"\n",
    "# dummy = Model(\"dummy\", dummy_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# baseline_logistic 'baseline_log', LogisticRegression(verbose=1, n_jobs=4\n",
    "# baseline = Model(\"baseline_log\", baseline_logistic, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 'baseline_log__C': 1, 'baseline_log__fit_intercept': True, 'baseline_log__max_iter': 100,'baseline_log__penalty': 'l2',\n",
    "# 'baseline_log__solver': 'sag', 'baseline_log__tol': 0.0001\n",
    "# gridsearch1 = Model(\"gridsearch1\", grid_log, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# (\"smote\", SMOTE(n_jobs= 4, sampling_strategy='auto')\n",
    "# smote1 = Model(\"smote1\", smote_pipeline, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# ('baseline_log', LogisticRegression(C=.01, max_iter=200, solver='newton-cg', verbose=1, n_jobs=4)\n",
    "# log2 = Model(\"logistic2\", logistic2, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# poly_int -> same as above, polynomial interaction only\n",
    "# interactions = Model(\"int_only\", poly_int, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# poly2 -> now with degree two\n",
    "# degree2 = Model(\"poly_deg_2\", poly2, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# (no poly ->'baseline_log', LogisticRegression(C=.01, max_iter=1000, solver='newton-cg', verbose=1, n_jobs=4))\n",
    "# max_i = Model(\"max_i_1000\", max_iter, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# lbfgs -> same as above but different solver\n",
    "# lbfgs = Model(\"lbfgs\", lbfgs, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# (\"smote\", SMOTE(n_jobs= 4, sampling_strategy={0:24161,1:12000,2: 17146})\n",
    "# smote_d = Model(\"smote_dict1\", smote_dict, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_prec</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummy</td>\n",
       "      <td>0.542334</td>\n",
       "      <td>0.180778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>15.807208</td>\n",
       "      <td>0.545320</td>\n",
       "      <td>0.181773</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>15.704096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline_log</td>\n",
       "      <td>0.763098</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.591662</td>\n",
       "      <td>0.613699</td>\n",
       "      <td>0.577305</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.697416</td>\n",
       "      <td>0.592629</td>\n",
       "      <td>0.614711</td>\n",
       "      <td>0.571270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gridsearch1</td>\n",
       "      <td>0.761571</td>\n",
       "      <td>0.719763</td>\n",
       "      <td>0.575277</td>\n",
       "      <td>0.594477</td>\n",
       "      <td>0.586064</td>\n",
       "      <td>0.763098</td>\n",
       "      <td>0.708619</td>\n",
       "      <td>0.574679</td>\n",
       "      <td>0.592508</td>\n",
       "      <td>0.580114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smote1</td>\n",
       "      <td>0.675578</td>\n",
       "      <td>0.607805</td>\n",
       "      <td>0.680058</td>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.720017</td>\n",
       "      <td>0.671111</td>\n",
       "      <td>0.608147</td>\n",
       "      <td>0.684890</td>\n",
       "      <td>0.600826</td>\n",
       "      <td>0.716779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic2</td>\n",
       "      <td>0.748979</td>\n",
       "      <td>0.721377</td>\n",
       "      <td>0.540635</td>\n",
       "      <td>0.545412</td>\n",
       "      <td>0.614213</td>\n",
       "      <td>0.751313</td>\n",
       "      <td>0.711600</td>\n",
       "      <td>0.544614</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>0.607817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>int_only</td>\n",
       "      <td>0.749585</td>\n",
       "      <td>0.725608</td>\n",
       "      <td>0.543306</td>\n",
       "      <td>0.549996</td>\n",
       "      <td>0.611666</td>\n",
       "      <td>0.751380</td>\n",
       "      <td>0.720979</td>\n",
       "      <td>0.546715</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.605992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poly_deg_2</td>\n",
       "      <td>0.749585</td>\n",
       "      <td>0.725608</td>\n",
       "      <td>0.543306</td>\n",
       "      <td>0.549996</td>\n",
       "      <td>0.611666</td>\n",
       "      <td>0.751380</td>\n",
       "      <td>0.720979</td>\n",
       "      <td>0.546715</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.605992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max_i_1000</td>\n",
       "      <td>0.749585</td>\n",
       "      <td>0.725608</td>\n",
       "      <td>0.543306</td>\n",
       "      <td>0.549996</td>\n",
       "      <td>0.611666</td>\n",
       "      <td>0.751380</td>\n",
       "      <td>0.720979</td>\n",
       "      <td>0.546715</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.605992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.749562</td>\n",
       "      <td>0.725586</td>\n",
       "      <td>0.543292</td>\n",
       "      <td>0.549981</td>\n",
       "      <td>0.611663</td>\n",
       "      <td>0.751380</td>\n",
       "      <td>0.720979</td>\n",
       "      <td>0.546715</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.605992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smote_dict1</td>\n",
       "      <td>0.707003</td>\n",
       "      <td>0.620109</td>\n",
       "      <td>0.670849</td>\n",
       "      <td>0.621051</td>\n",
       "      <td>0.671317</td>\n",
       "      <td>0.708822</td>\n",
       "      <td>0.621274</td>\n",
       "      <td>0.673983</td>\n",
       "      <td>0.622540</td>\n",
       "      <td>0.662777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  train_accuracy  train_prec  train_recall  train_f1  \\\n",
       "0         dummy        0.542334    0.180778      0.333333  0.234421   \n",
       "1  baseline_log        0.763098    0.700565      0.591662  0.613699   \n",
       "2   gridsearch1        0.761571    0.719763      0.575277  0.594477   \n",
       "3        smote1        0.675578    0.607805      0.680058  0.602763   \n",
       "4     logistic2        0.748979    0.721377      0.540635  0.545412   \n",
       "5      int_only        0.749585    0.725608      0.543306  0.549996   \n",
       "6    poly_deg_2        0.749585    0.725608      0.543306  0.549996   \n",
       "7    max_i_1000        0.749585    0.725608      0.543306  0.549996   \n",
       "8         lbfgs        0.749562    0.725586      0.543292  0.549981   \n",
       "9   smote_dict1        0.707003    0.620109      0.670849  0.621051   \n",
       "\n",
       "   train_logloss  test_accuracy  test_prec  test_recall   test_f1  \\\n",
       "0      15.807208       0.545320   0.181773     0.333333  0.235257   \n",
       "1       0.577305       0.763636   0.697416     0.592629  0.614711   \n",
       "2       0.586064       0.763098   0.708619     0.574679  0.592508   \n",
       "3       0.720017       0.671111   0.608147     0.684890  0.600826   \n",
       "4       0.614213       0.751313   0.711600     0.544614  0.552147   \n",
       "5       0.611666       0.751380   0.720979     0.546715  0.555686   \n",
       "6       0.611666       0.751380   0.720979     0.546715  0.555686   \n",
       "7       0.611666       0.751380   0.720979     0.546715  0.555686   \n",
       "8       0.611663       0.751380   0.720979     0.546715  0.555686   \n",
       "9       0.671317       0.708822   0.621274     0.673983  0.622540   \n",
       "\n",
       "   test_logloss  \n",
       "0     15.704096  \n",
       "1      0.571270  \n",
       "2      0.580114  \n",
       "3      0.716779  \n",
       "4      0.607817  \n",
       "5      0.605992  \n",
       "6      0.605992  \n",
       "7      0.605992  \n",
       "8      0.605992  \n",
       "9      0.662777  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After failing to improve upon the baseline Logistic Regression, I determined that grid searching multiple 5k samples to determine the best hyper-parameters would be the best course of action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "CT\n",
      "baseline_log\n",
      "CT__n_jobs\n",
      "CT__remainder\n",
      "CT__sparse_threshold\n",
      "CT__transformer_weights\n",
      "CT__transformers\n",
      "CT__verbose\n",
      "CT__subpipe_numerics\n",
      "CT__subpipe_cat\n",
      "CT__subpipe_numerics__memory\n",
      "CT__subpipe_numerics__steps\n",
      "CT__subpipe_numerics__verbose\n",
      "CT__subpipe_numerics__mean_impute\n",
      "CT__subpipe_numerics__ss\n",
      "CT__subpipe_numerics__mean_impute__add_indicator\n",
      "CT__subpipe_numerics__mean_impute__copy\n",
      "CT__subpipe_numerics__mean_impute__fill_value\n",
      "CT__subpipe_numerics__mean_impute__missing_values\n",
      "CT__subpipe_numerics__mean_impute__strategy\n",
      "CT__subpipe_numerics__mean_impute__verbose\n",
      "CT__subpipe_numerics__ss__copy\n",
      "CT__subpipe_numerics__ss__with_mean\n",
      "CT__subpipe_numerics__ss__with_std\n",
      "CT__subpipe_cat__memory\n",
      "CT__subpipe_cat__steps\n",
      "CT__subpipe_cat__verbose\n",
      "CT__subpipe_cat__cat_impute\n",
      "CT__subpipe_cat__ohe\n",
      "CT__subpipe_cat__cat_impute__add_indicator\n",
      "CT__subpipe_cat__cat_impute__copy\n",
      "CT__subpipe_cat__cat_impute__fill_value\n",
      "CT__subpipe_cat__cat_impute__missing_values\n",
      "CT__subpipe_cat__cat_impute__strategy\n",
      "CT__subpipe_cat__cat_impute__verbose\n",
      "CT__subpipe_cat__ohe__categories\n",
      "CT__subpipe_cat__ohe__drop\n",
      "CT__subpipe_cat__ohe__dtype\n",
      "CT__subpipe_cat__ohe__handle_unknown\n",
      "CT__subpipe_cat__ohe__sparse\n",
      "baseline_log__C\n",
      "baseline_log__class_weight\n",
      "baseline_log__dual\n",
      "baseline_log__fit_intercept\n",
      "baseline_log__intercept_scaling\n",
      "baseline_log__l1_ratio\n",
      "baseline_log__max_iter\n",
      "baseline_log__multi_class\n",
      "baseline_log__n_jobs\n",
      "baseline_log__penalty\n",
      "baseline_log__random_state\n",
      "baseline_log__solver\n",
      "baseline_log__tol\n",
      "baseline_log__verbose\n",
      "baseline_log__warm_start\n"
     ]
    }
   ],
   "source": [
    "for i in baseline_logistic.get_params().keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing a starting dictionary of parameters and optional values\n",
    "parameters = {\n",
    "    \"baseline_log__tol\": [.0001, .001, .01],\n",
    "    \"baseline_log__C\": [1, .1, .01],\n",
    "    \"baseline_log__fit_intercept\": [True, False],\n",
    "    \"baseline_log__solver\": ['newton-cg', 'sag', 'lbfgs'],\n",
    "    \"baseline_log__max_iter\": [100, 250, 500, 1000, 2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1350"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*3*2*3*3*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search1 = GridSearchCV(\n",
    "    estimator=baseline_logistic,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Final Grid Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 1350 out of 1350 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing CT, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 0 seconds\n",
      "[Pipeline] ...... (step 2 of 2) Processing baseline_log, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samalainabayeva/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('CT',\n",
       "                                        ColumnTransformer(n_jobs=4,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_numerics',\n",
       "                                                                         Pipeline(steps=[('mean_impute',\n",
       "                                                                                          SimpleImputer(add_indicator=True)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())],\n",
       "                                                                                  verbose=True),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f83f2e05490>),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(step...\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f83f2e05b50>)],\n",
       "                                                          verbose=True)),\n",
       "                                       ('baseline_log',\n",
       "                                        LogisticRegression(n_jobs=4,\n",
       "                                                           verbose=1))],\n",
       "                                verbose=True),\n",
       "             n_jobs=4,\n",
       "             param_grid={'baseline_log__C': [1, 0.1, 0.01],\n",
       "                         'baseline_log__fit_intercept': [True, False],\n",
       "                         'baseline_log__max_iter': [100, 250, 500, 1000, 2000],\n",
       "                         'baseline_log__solver': ['newton-cg', 'sag', 'lbfgs'],\n",
       "                         'baseline_log__tol': [0.0001, 0.001, 0.01]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_log__C': 1,\n",
       " 'baseline_log__fit_intercept': True,\n",
       " 'baseline_log__max_iter': 100,\n",
       " 'baseline_log__solver': 'sag',\n",
       " 'baseline_log__tol': 0.0001}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Grid Search 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data2 = df.sample(5000, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search2 = GridSearchCV(\n",
    "    estimator=baseline_logistic,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done 1350 out of 1350 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing CT, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 0 seconds\n",
      "[Pipeline] ...... (step 2 of 2) Processing baseline_log, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samalainabayeva/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('CT',\n",
       "                                        ColumnTransformer(n_jobs=4,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_numerics',\n",
       "                                                                         Pipeline(steps=[('mean_impute',\n",
       "                                                                                          SimpleImputer(add_indicator=True)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())],\n",
       "                                                                                  verbose=True),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f83f2e05490>),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(step...\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f83f2e05b50>)],\n",
       "                                                          verbose=True)),\n",
       "                                       ('baseline_log',\n",
       "                                        LogisticRegression(n_jobs=4,\n",
       "                                                           verbose=1))],\n",
       "                                verbose=True),\n",
       "             n_jobs=4,\n",
       "             param_grid={'baseline_log__C': [1, 0.1, 0.01],\n",
       "                         'baseline_log__fit_intercept': [True, False],\n",
       "                         'baseline_log__max_iter': [100, 250, 500, 1000, 2000],\n",
       "                         'baseline_log__solver': ['newton-cg', 'sag', 'lbfgs'],\n",
       "                         'baseline_log__tol': [0.0001, 0.001, 0.01]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = sample_data2.drop(\"Target\", axis= 1)\n",
    "y_2 = sample_data2['Target']\n",
    "\n",
    "grid_search2.fit(X_2, y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_log__C': 1,\n",
       " 'baseline_log__fit_intercept': True,\n",
       " 'baseline_log__max_iter': 100,\n",
       " 'baseline_log__solver': 'sag',\n",
       " 'baseline_log__tol': 0.001}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Grid Search 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search3 = GridSearchCV(\n",
    "    estimator=baseline_logistic,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data3 = df.sample(5000, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 1005 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 1350 out of 1350 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing CT, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 2 of 2) Processing baseline_log, total=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('CT',\n",
       "                                        ColumnTransformer(n_jobs=4,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          transformers=[('subpipe_numerics',\n",
       "                                                                         Pipeline(steps=[('mean_impute',\n",
       "                                                                                          SimpleImputer(add_indicator=True)),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())],\n",
       "                                                                                  verbose=True),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f83f2e05490>),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(step...\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f83f2e05b50>)],\n",
       "                                                          verbose=True)),\n",
       "                                       ('baseline_log',\n",
       "                                        LogisticRegression(n_jobs=4,\n",
       "                                                           verbose=1))],\n",
       "                                verbose=True),\n",
       "             n_jobs=4,\n",
       "             param_grid={'baseline_log__C': [1, 0.1, 0.01],\n",
       "                         'baseline_log__fit_intercept': [True, False],\n",
       "                         'baseline_log__max_iter': [100, 250, 500, 1000, 2000],\n",
       "                         'baseline_log__solver': ['newton-cg', 'sag', 'lbfgs'],\n",
       "                         'baseline_log__tol': [0.0001, 0.001, 0.01]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3 = sample_data3.drop(\"Target\", axis=1) \n",
    "y_3 = sample_data3['Target']\n",
    "\n",
    "grid_search3.fit(X_3, y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_log__C': 1,\n",
       " 'baseline_log__fit_intercept': True,\n",
       " 'baseline_log__max_iter': 100,\n",
       " 'baseline_log__solver': 'sag',\n",
       " 'baseline_log__tol': 0.0001}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_log__C': 1,\n",
       " 'baseline_log__fit_intercept': True,\n",
       " 'baseline_log__max_iter': 100,\n",
       " 'baseline_log__solver': 'sag',\n",
       " 'baseline_log__tol': 0.001}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_log__C': 0.1,\n",
       " 'baseline_log__fit_intercept': True,\n",
       " 'baseline_log__max_iter': 100,\n",
       " 'baseline_log__solver': 'newton-cg',\n",
       " 'baseline_log__tol': 0.0001}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is very consistent agreement on the max_iters = 100 and fit_intercept = True. \n",
    "- C 2-to-1 = 1\n",
    "- Solver 2-to-1 = 'sag'\n",
    "- tolerance 2-to-1 = 0.0001\n",
    "\n",
    "So the final model would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model = LogisticRegression(C=1, tol=0.0001, fit_intercept=True, solver='sag', max_iter=100, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Pipeline(steps=[\n",
    "    ('CT', CT),\n",
    "    ('baseline_log', LogisticRegression(C=1, tol=0.0001, fit_intercept=True, solver='sag', max_iter=100, n_jobs=4, \n",
    "                                       verbose=1))\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ................ (step 1 of 2) Processing CT, total=   9.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 8 seconds\n",
      "[Pipeline] ...... (step 2 of 2) Processing baseline_log, total=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samalainabayeva/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    8.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('CT',\n",
       "                 ColumnTransformer(n_jobs=4, remainder='passthrough',\n",
       "                                   transformers=[('subpipe_numerics',\n",
       "                                                  Pipeline(steps=[('mean_impute',\n",
       "                                                                   SimpleImputer(add_indicator=True)),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  ('poly',\n",
       "                                                                   PolynomialFeatures(interaction_only=True))],\n",
       "                                                           verbose=True),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f82e87f5820>),\n",
       "                                                 ('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('cat_impute',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))],\n",
       "                                                           verbose=True),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f82e87f5910>)],\n",
       "                                   verbose=True)),\n",
       "                ('baseline_log',\n",
       "                 LogisticRegression(C=1, n_jobs=4, solver='sag', verbose=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   25.0s finished\n"
     ]
    }
   ],
   "source": [
    "final = Model(\"final_model\", final_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_prec</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummy</td>\n",
       "      <td>0.542334</td>\n",
       "      <td>0.180778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>15.807208</td>\n",
       "      <td>0.545320</td>\n",
       "      <td>0.181773</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>15.704096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline_log</td>\n",
       "      <td>0.763098</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.591662</td>\n",
       "      <td>0.613699</td>\n",
       "      <td>0.577305</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.697416</td>\n",
       "      <td>0.592629</td>\n",
       "      <td>0.614711</td>\n",
       "      <td>0.571270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gridsearch1</td>\n",
       "      <td>0.761571</td>\n",
       "      <td>0.719763</td>\n",
       "      <td>0.575277</td>\n",
       "      <td>0.594477</td>\n",
       "      <td>0.586064</td>\n",
       "      <td>0.763098</td>\n",
       "      <td>0.708619</td>\n",
       "      <td>0.574679</td>\n",
       "      <td>0.592508</td>\n",
       "      <td>0.580114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smote1</td>\n",
       "      <td>0.675578</td>\n",
       "      <td>0.607805</td>\n",
       "      <td>0.680058</td>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.720017</td>\n",
       "      <td>0.671111</td>\n",
       "      <td>0.608147</td>\n",
       "      <td>0.684890</td>\n",
       "      <td>0.600826</td>\n",
       "      <td>0.716779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic2</td>\n",
       "      <td>0.748979</td>\n",
       "      <td>0.721377</td>\n",
       "      <td>0.540635</td>\n",
       "      <td>0.545412</td>\n",
       "      <td>0.614213</td>\n",
       "      <td>0.751313</td>\n",
       "      <td>0.711600</td>\n",
       "      <td>0.544614</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>0.607817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>int_only</td>\n",
       "      <td>0.749585</td>\n",
       "      <td>0.725608</td>\n",
       "      <td>0.543306</td>\n",
       "      <td>0.549996</td>\n",
       "      <td>0.611666</td>\n",
       "      <td>0.751380</td>\n",
       "      <td>0.720979</td>\n",
       "      <td>0.546715</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.605992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poly_deg_2</td>\n",
       "      <td>0.749585</td>\n",
       "      <td>0.725608</td>\n",
       "      <td>0.543306</td>\n",
       "      <td>0.549996</td>\n",
       "      <td>0.611666</td>\n",
       "      <td>0.751380</td>\n",
       "      <td>0.720979</td>\n",
       "      <td>0.546715</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.605992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max_i_1000</td>\n",
       "      <td>0.749585</td>\n",
       "      <td>0.725608</td>\n",
       "      <td>0.543306</td>\n",
       "      <td>0.549996</td>\n",
       "      <td>0.611666</td>\n",
       "      <td>0.751380</td>\n",
       "      <td>0.720979</td>\n",
       "      <td>0.546715</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.605992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.749562</td>\n",
       "      <td>0.725586</td>\n",
       "      <td>0.543292</td>\n",
       "      <td>0.549981</td>\n",
       "      <td>0.611663</td>\n",
       "      <td>0.751380</td>\n",
       "      <td>0.720979</td>\n",
       "      <td>0.546715</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>0.605992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>smote_dict1</td>\n",
       "      <td>0.707003</td>\n",
       "      <td>0.620109</td>\n",
       "      <td>0.670849</td>\n",
       "      <td>0.621051</td>\n",
       "      <td>0.671317</td>\n",
       "      <td>0.708822</td>\n",
       "      <td>0.621274</td>\n",
       "      <td>0.673983</td>\n",
       "      <td>0.622540</td>\n",
       "      <td>0.662777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>final_model</td>\n",
       "      <td>0.744669</td>\n",
       "      <td>0.710404</td>\n",
       "      <td>0.537723</td>\n",
       "      <td>0.542535</td>\n",
       "      <td>0.621116</td>\n",
       "      <td>0.744108</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.538227</td>\n",
       "      <td>0.545091</td>\n",
       "      <td>0.620135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  train_accuracy  train_prec  train_recall  train_f1  \\\n",
       "0          dummy        0.542334    0.180778      0.333333  0.234421   \n",
       "1   baseline_log        0.763098    0.700565      0.591662  0.613699   \n",
       "2    gridsearch1        0.761571    0.719763      0.575277  0.594477   \n",
       "3         smote1        0.675578    0.607805      0.680058  0.602763   \n",
       "4      logistic2        0.748979    0.721377      0.540635  0.545412   \n",
       "5       int_only        0.749585    0.725608      0.543306  0.549996   \n",
       "6     poly_deg_2        0.749585    0.725608      0.543306  0.549996   \n",
       "7     max_i_1000        0.749585    0.725608      0.543306  0.549996   \n",
       "8          lbfgs        0.749562    0.725586      0.543292  0.549981   \n",
       "9    smote_dict1        0.707003    0.620109      0.670849  0.621051   \n",
       "10   final_model        0.744669    0.710404      0.537723  0.542535   \n",
       "\n",
       "    train_logloss  test_accuracy  test_prec  test_recall   test_f1  \\\n",
       "0       15.807208       0.545320   0.181773     0.333333  0.235257   \n",
       "1        0.577305       0.763636   0.697416     0.592629  0.614711   \n",
       "2        0.586064       0.763098   0.708619     0.574679  0.592508   \n",
       "3        0.720017       0.671111   0.608147     0.684890  0.600826   \n",
       "4        0.614213       0.751313   0.711600     0.544614  0.552147   \n",
       "5        0.611666       0.751380   0.720979     0.546715  0.555686   \n",
       "6        0.611666       0.751380   0.720979     0.546715  0.555686   \n",
       "7        0.611666       0.751380   0.720979     0.546715  0.555686   \n",
       "8        0.611663       0.751380   0.720979     0.546715  0.555686   \n",
       "9        0.671317       0.708822   0.621274     0.673983  0.622540   \n",
       "10       0.621116       0.744108   0.711111     0.538227  0.545091   \n",
       "\n",
       "    test_logloss  \n",
       "0      15.704096  \n",
       "1       0.571270  \n",
       "2       0.580114  \n",
       "3       0.716779  \n",
       "4       0.607817  \n",
       "5       0.605992  \n",
       "6       0.605992  \n",
       "7       0.605992  \n",
       "8       0.605992  \n",
       "9       0.662777  \n",
       "10      0.620135  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After grid searching for optimized hyperparameters, the best performing model was still the baseline logistic regression without any kind of tweaking whatsoever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.model_df.to_csv('/Users/samalainabayeva/Desktop/Water Project CSVs/final_metrics_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_log_loss</th>\n",
       "      <th>name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_logloss</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>train_prec</th>\n",
       "      <th>train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.542334</td>\n",
       "      <td>15.807208</td>\n",
       "      <td>0.545320</td>\n",
       "      <td>15.704096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>logistic_1</td>\n",
       "      <td>0.771762</td>\n",
       "      <td>0.577305</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.598705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>grid_logistic_1</td>\n",
       "      <td>0.766981</td>\n",
       "      <td>0.586082</td>\n",
       "      <td>0.763030</td>\n",
       "      <td>0.596011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>smote_1</td>\n",
       "      <td>0.683659</td>\n",
       "      <td>0.720839</td>\n",
       "      <td>0.669091</td>\n",
       "      <td>0.733580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lr_C.01_mi200_solv_n.cg</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614420</td>\n",
       "      <td>0.750976</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>c.01_mi200_svr_ncg_tol_1</td>\n",
       "      <td>0.677621</td>\n",
       "      <td>0.747923</td>\n",
       "      <td>0.668215</td>\n",
       "      <td>0.773572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>poly1_lr_C.01_mi200_solv_n.cg</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614420</td>\n",
       "      <td>0.750976</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>poly2_lr_C.01_mi1000_solv_n.cg</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614420</td>\n",
       "      <td>0.750976</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>saga_l1_mi1000</td>\n",
       "      <td>0.727452</td>\n",
       "      <td>0.663176</td>\n",
       "      <td>0.728013</td>\n",
       "      <td>0.699459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614422</td>\n",
       "      <td>0.750909</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs_fi</td>\n",
       "      <td>0.753401</td>\n",
       "      <td>0.614213</td>\n",
       "      <td>0.751246</td>\n",
       "      <td>0.642047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>new_cg</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.614213</td>\n",
       "      <td>0.751313</td>\n",
       "      <td>0.642047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>new_low_c</td>\n",
       "      <td>0.730640</td>\n",
       "      <td>0.678024</td>\n",
       "      <td>0.731582</td>\n",
       "      <td>0.721139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>numeric_only</td>\n",
       "      <td>0.615690</td>\n",
       "      <td>0.678024</td>\n",
       "      <td>0.620741</td>\n",
       "      <td>0.721139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>dropped3cols</td>\n",
       "      <td>0.727520</td>\n",
       "      <td>0.678024</td>\n",
       "      <td>0.727340</td>\n",
       "      <td>0.721139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>minmax_baseline</td>\n",
       "      <td>0.771762</td>\n",
       "      <td>0.577305</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.598705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>median_fill, min_max</td>\n",
       "      <td>0.771762</td>\n",
       "      <td>0.577305</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.598705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>median_fill_2, min_max</td>\n",
       "      <td>0.771560</td>\n",
       "      <td>0.577373</td>\n",
       "      <td>0.764714</td>\n",
       "      <td>0.598045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dummy_classifier</td>\n",
       "      <td>0.54532</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>15.704096</td>\n",
       "      <td>0.181773</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.542334</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>15.807208</td>\n",
       "      <td>0.180778</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dummy_classifier</td>\n",
       "      <td>0.54532</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>15.704096</td>\n",
       "      <td>0.181773</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.542334</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>15.807208</td>\n",
       "      <td>0.180778</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                            Name  train_score  train_log_loss  \\\n",
       "0            0                           dummy     0.542334       15.807208   \n",
       "1            1                      logistic_1     0.771762        0.577305   \n",
       "2            2                 grid_logistic_1     0.766981        0.586082   \n",
       "3            3                         smote_1     0.683659        0.720839   \n",
       "4            4         lr_C.01_mi200_solv_n.cg     0.753378        0.614420   \n",
       "5            5        c.01_mi200_svr_ncg_tol_1     0.677621        0.747923   \n",
       "6            6   poly1_lr_C.01_mi200_solv_n.cg     0.753378        0.614420   \n",
       "7            7  poly2_lr_C.01_mi1000_solv_n.cg     0.753378        0.614420   \n",
       "8            8                  saga_l1_mi1000     0.727452        0.663176   \n",
       "9            9                           lbfgs     0.753378        0.614422   \n",
       "10          10                        lbfgs_fi     0.753401        0.614213   \n",
       "11          11                          new_cg     0.753378        0.614213   \n",
       "12          12                       new_low_c     0.730640        0.678024   \n",
       "13          13                    numeric_only     0.615690        0.678024   \n",
       "14          14                    dropped3cols     0.727520        0.678024   \n",
       "15          15                 minmax_baseline     0.771762        0.577305   \n",
       "16          16            median_fill, min_max     0.771762        0.577305   \n",
       "17          17          median_fill_2, min_max     0.771560        0.577373   \n",
       "18          18                             NaN          NaN             NaN   \n",
       "19          19                             NaN          NaN             NaN   \n",
       "\n",
       "    test_score  test_log_loss              name  test_accuracy   test_f1  \\\n",
       "0     0.545320      15.704096               NaN            NaN       NaN   \n",
       "1     0.763636       0.598705               NaN            NaN       NaN   \n",
       "2     0.763030       0.596011               NaN            NaN       NaN   \n",
       "3     0.669091       0.733580               NaN            NaN       NaN   \n",
       "4     0.750976       0.642552               NaN            NaN       NaN   \n",
       "5     0.668215       0.773572               NaN            NaN       NaN   \n",
       "6     0.750976       0.642552               NaN            NaN       NaN   \n",
       "7     0.750976       0.642552               NaN            NaN       NaN   \n",
       "8     0.728013       0.699459               NaN            NaN       NaN   \n",
       "9     0.750909       0.642552               NaN            NaN       NaN   \n",
       "10    0.751246       0.642047               NaN            NaN       NaN   \n",
       "11    0.751313       0.642047               NaN            NaN       NaN   \n",
       "12    0.731582       0.721139               NaN            NaN       NaN   \n",
       "13    0.620741       0.721139               NaN            NaN       NaN   \n",
       "14    0.727340       0.721139               NaN            NaN       NaN   \n",
       "15    0.763636       0.598705               NaN            NaN       NaN   \n",
       "16    0.763636       0.598705               NaN            NaN       NaN   \n",
       "17    0.764714       0.598045               NaN            NaN       NaN   \n",
       "18         NaN            NaN  dummy_classifier        0.54532  0.235257   \n",
       "19         NaN            NaN  dummy_classifier        0.54532  0.235257   \n",
       "\n",
       "    test_logloss  test_prec  test_recall  train_accuracy  train_f1  \\\n",
       "0            NaN        NaN          NaN             NaN       NaN   \n",
       "1            NaN        NaN          NaN             NaN       NaN   \n",
       "2            NaN        NaN          NaN             NaN       NaN   \n",
       "3            NaN        NaN          NaN             NaN       NaN   \n",
       "4            NaN        NaN          NaN             NaN       NaN   \n",
       "5            NaN        NaN          NaN             NaN       NaN   \n",
       "6            NaN        NaN          NaN             NaN       NaN   \n",
       "7            NaN        NaN          NaN             NaN       NaN   \n",
       "8            NaN        NaN          NaN             NaN       NaN   \n",
       "9            NaN        NaN          NaN             NaN       NaN   \n",
       "10           NaN        NaN          NaN             NaN       NaN   \n",
       "11           NaN        NaN          NaN             NaN       NaN   \n",
       "12           NaN        NaN          NaN             NaN       NaN   \n",
       "13           NaN        NaN          NaN             NaN       NaN   \n",
       "14           NaN        NaN          NaN             NaN       NaN   \n",
       "15           NaN        NaN          NaN             NaN       NaN   \n",
       "16           NaN        NaN          NaN             NaN       NaN   \n",
       "17           NaN        NaN          NaN             NaN       NaN   \n",
       "18     15.704096   0.181773     0.333333        0.542334  0.234421   \n",
       "19     15.704096   0.181773     0.333333        0.542334  0.234421   \n",
       "\n",
       "    train_logloss  train_prec  train_recall  \n",
       "0             NaN         NaN           NaN  \n",
       "1             NaN         NaN           NaN  \n",
       "2             NaN         NaN           NaN  \n",
       "3             NaN         NaN           NaN  \n",
       "4             NaN         NaN           NaN  \n",
       "5             NaN         NaN           NaN  \n",
       "6             NaN         NaN           NaN  \n",
       "7             NaN         NaN           NaN  \n",
       "8             NaN         NaN           NaN  \n",
       "9             NaN         NaN           NaN  \n",
       "10            NaN         NaN           NaN  \n",
       "11            NaN         NaN           NaN  \n",
       "12            NaN         NaN           NaN  \n",
       "13            NaN         NaN           NaN  \n",
       "14            NaN         NaN           NaN  \n",
       "15            NaN         NaN           NaN  \n",
       "16            NaN         NaN           NaN  \n",
       "17            NaN         NaN           NaN  \n",
       "18      15.807208    0.180778      0.333333  \n",
       "19      15.807208    0.180778      0.333333  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.669742</td>\n",
       "      <td>0.665051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Smote_grid1</td>\n",
       "      <td>0.669742</td>\n",
       "      <td>0.665051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline_log</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.765051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline_log</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.765051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline_log_grid</td>\n",
       "      <td>0.766846</td>\n",
       "      <td>0.764781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>poly1</td>\n",
       "      <td>0.772435</td>\n",
       "      <td>0.768822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Poly_grid_1</td>\n",
       "      <td>0.772435</td>\n",
       "      <td>0.768822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>poly2</td>\n",
       "      <td>0.770168</td>\n",
       "      <td>0.766128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Poly_grid_3</td>\n",
       "      <td>0.772435</td>\n",
       "      <td>0.768822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>poly_smote</td>\n",
       "      <td>0.684040</td>\n",
       "      <td>0.677980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>dates1</td>\n",
       "      <td>0.768822</td>\n",
       "      <td>0.763771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Dates_grid</td>\n",
       "      <td>0.772256</td>\n",
       "      <td>0.767946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0               Name  train_score  test_score\n",
       "0            0                  0     0.000000    0.000000\n",
       "1            0           baseline     0.669742    0.665051\n",
       "2            0        Smote_grid1     0.669742    0.665051\n",
       "3            0       Baseline_log     0.769921    0.765051\n",
       "4            0       Baseline_log     0.769921    0.765051\n",
       "5            0  Baseline_log_grid     0.766846    0.764781\n",
       "6            0              poly1     0.772435    0.768822\n",
       "7            0        Poly_grid_1     0.772435    0.768822\n",
       "8            0              poly2     0.770168    0.766128\n",
       "9            0        Poly_grid_3     0.772435    0.768822\n",
       "10           0         poly_smote     0.684040    0.677980\n",
       "11           0             dates1     0.768822    0.763771\n",
       "12           0         Dates_grid     0.772256    0.767946"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "- Changing sampling strategy to \"auto\" made no difference in SMOTE hyperparameters.\n",
    "- Baseline log grid slightly worse than the uncalibrated logistic regression\n",
    "- For polynomial features, the grid search did not improve the default settings at all, still not overfit\n",
    "- After a 2 hour grid search, the best model only equals the best score thus far, still without overfitting, but without any improvement either.\n",
    "- Polynomial degree 2 + smote improved upon the baseline smote, but still performed worse than other models\n",
    "\n",
    "- Adding the dates_passed column improved the model very slightly. I will now re-check cleaning/feature selection.\n",
    "#### Returning to the baseline logistic regression model and modifying from there\n",
    "- Baseline Logistic Regression continues to be the best model\n",
    "- StandardScaler and MinMaxScaler produced the same exact results\n",
    "- Median fill and mean fill produced identical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
